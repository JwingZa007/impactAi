{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-12T15:08:27.482284Z",
     "start_time": "2025-03-12T15:06:07.715561Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'IMPACT.sensors.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure timestamp exists\n",
    "timestamp_column = 'createdAt'\n",
    "data[timestamp_column] = pd.to_datetime(data[timestamp_column])\n",
    "\n",
    "# Sort data\n",
    "data = data.sort_values(by=timestamp_column)\n",
    "\n",
    "# Select features and target\n",
    "features = ['temperature']\n",
    "data_features = data[features]\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data_features)\n",
    "\n",
    "# Save the scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, 'temperature_scaler.pkl')\n",
    "\n",
    "# Define sequence length and prediction steps\n",
    "sequence_length = 12  # Using past 10 steps (100 min)\n",
    "prediction_steps = [6, 12, 18, 24, 30, 36, 42, 48]  # Predict 1-8 hours ahead (10 min intervals)\n",
    "\n",
    "# Prepare sequences and targets\n",
    "def create_future_sequences(data, sequence_length, prediction_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - max(prediction_steps)):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        future_values = [np.mean(data[i + sequence_length + p: i + sequence_length + p + 6]) for p in prediction_steps]\n",
    "        y.append(np.array(future_values).flatten())\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_future_sequences(data_normalized, sequence_length, prediction_steps)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build GRU Model\n",
    "input_layer = Input(shape=(sequence_length, len(features)))\n",
    "x = GRU(64, activation='relu', return_sequences=True)(input_layer)\n",
    "x = GRU(32, activation='relu', return_sequences=False)(x)\n",
    "dense1 = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(len(prediction_steps), activation='linear')(dense1)\n",
    "\n",
    "# Build and compile model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=42, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss (MSE):\", test_loss)\n",
    "\n",
    "# Calculate additional evaluation metrics\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred, prediction_steps):\n",
    "    print(\"\\nStep-wise Performance Evaluation:\")\n",
    "    for idx, step in enumerate(prediction_steps):\n",
    "        hours = (step * 10) // 60\n",
    "        minutes = (step * 10) % 60\n",
    "        y_true_step = y_true[:, idx]\n",
    "        y_pred_step = y_pred[:, idx]\n",
    "\n",
    "        r2 = r2_score(y_true_step, y_pred_step)\n",
    "        mae = mean_absolute_error(y_true_step, y_pred_step)\n",
    "        print(f\"{hours}h{minutes:02d}min: R²={r2:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "    overall_r2 = r2_score(y_test, y_pred)\n",
    "    overall_mae = mean_absolute_error(y_test, y_pred)\n",
    "    print(\"\\nOverall Performance:\")\n",
    "    print(f\"Overall R² Score: {overall_r2:.2f}\")\n",
    "    print(f\"Overall Mean Absolute Error (MAE): {overall_mae:.2f}\")\n",
    "\n",
    "evaluate_predictions(y_test, y_pred, prediction_steps)\n",
    "\n",
    "# Save the model\n",
    "model.save('temperature_prediction_gru_model.keras')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "491/491 [==============================] - 7s 8ms/step - loss: 0.0091 - val_loss: 4.4697e-04\n",
      "Epoch 2/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4569e-04 - val_loss: 4.2116e-04\n",
      "Epoch 3/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.6197e-04 - val_loss: 4.3806e-04\n",
      "Epoch 4/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.5458e-04 - val_loss: 4.2110e-04\n",
      "Epoch 5/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4048e-04 - val_loss: 4.1622e-04\n",
      "Epoch 6/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4432e-04 - val_loss: 4.1888e-04\n",
      "Epoch 7/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4800e-04 - val_loss: 4.1605e-04\n",
      "Epoch 8/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4797e-04 - val_loss: 4.7078e-04\n",
      "Epoch 9/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.5208e-04 - val_loss: 4.1950e-04\n",
      "Epoch 10/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4515e-04 - val_loss: 4.3361e-04\n",
      "Epoch 11/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4212e-04 - val_loss: 4.0889e-04\n",
      "Epoch 12/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.4814e-04 - val_loss: 4.5262e-04\n",
      "Epoch 13/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2513e-04 - val_loss: 4.9036e-04\n",
      "Epoch 14/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.5536e-04 - val_loss: 4.2882e-04\n",
      "Epoch 15/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.3585e-04 - val_loss: 6.3969e-04\n",
      "Epoch 16/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.3319e-04 - val_loss: 4.1194e-04\n",
      "Epoch 17/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.3524e-04 - val_loss: 4.3214e-04\n",
      "Epoch 18/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.3692e-04 - val_loss: 4.3784e-04\n",
      "Epoch 19/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.4081e-04 - val_loss: 4.9088e-04\n",
      "Epoch 20/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.3197e-04 - val_loss: 5.7811e-04\n",
      "Epoch 21/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.3199e-04 - val_loss: 4.7489e-04\n",
      "Epoch 22/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2677e-04 - val_loss: 4.1817e-04\n",
      "Epoch 23/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.1901e-04 - val_loss: 5.6719e-04\n",
      "Epoch 24/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2238e-04 - val_loss: 4.2417e-04\n",
      "Epoch 25/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.1694e-04 - val_loss: 4.4634e-04\n",
      "Epoch 26/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2426e-04 - val_loss: 4.3922e-04\n",
      "Epoch 27/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2570e-04 - val_loss: 4.1308e-04\n",
      "Epoch 28/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.2927e-04 - val_loss: 4.2591e-04\n",
      "Epoch 29/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2452e-04 - val_loss: 4.0894e-04\n",
      "Epoch 30/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2432e-04 - val_loss: 4.1361e-04\n",
      "Epoch 31/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2457e-04 - val_loss: 4.3787e-04\n",
      "Epoch 32/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.1542e-04 - val_loss: 4.1229e-04\n",
      "Epoch 33/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.2421e-04 - val_loss: 4.9611e-04\n",
      "Epoch 34/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.1957e-04 - val_loss: 4.3861e-04\n",
      "Epoch 35/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.1591e-04 - val_loss: 3.9712e-04\n",
      "Epoch 36/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 4.1996e-04 - val_loss: 4.1806e-04\n",
      "Epoch 37/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.1247e-04 - val_loss: 3.9811e-04\n",
      "Epoch 38/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.1411e-04 - val_loss: 4.1428e-04\n",
      "Epoch 39/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.1752e-04 - val_loss: 4.1653e-04\n",
      "Epoch 40/42\n",
      "491/491 [==============================] - 4s 7ms/step - loss: 4.1120e-04 - val_loss: 5.5492e-04\n",
      "Epoch 41/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.2095e-04 - val_loss: 4.4033e-04\n",
      "Epoch 42/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 4.1796e-04 - val_loss: 4.5631e-04\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 4.5631e-04\n",
      "Test Loss (MSE): 0.0004563122056424618\n",
      "123/123 [==============================] - 1s 2ms/step\n",
      "\n",
      "Step-wise Performance Evaluation:\n",
      "1h00min: R²=0.99, MAE=0.01\n",
      "2h00min: R²=0.99, MAE=0.01\n",
      "3h00min: R²=0.99, MAE=0.01\n",
      "4h00min: R²=0.98, MAE=0.01\n",
      "5h00min: R²=0.98, MAE=0.01\n",
      "6h00min: R²=0.98, MAE=0.01\n",
      "7h00min: R²=0.98, MAE=0.02\n",
      "8h00min: R²=0.97, MAE=0.02\n",
      "\n",
      "Overall Performance:\n",
      "Overall R² Score: 0.98\n",
      "Overall Mean Absolute Error (MAE): 0.01\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T12:44:29.339845Z",
     "start_time": "2025-03-13T12:40:59.130155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import joblib\n",
    "\n",
    "# ------------------------------\n",
    "# 1. Data Reading and Preprocessing\n",
    "# ------------------------------\n",
    "file_path = 'IMPACT.sensors.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Timestamp processing\n",
    "timestamp_col = 'createdAt'\n",
    "data[timestamp_col] = pd.to_datetime(data[timestamp_col])\n",
    "data = data.sort_values(by=timestamp_col).reset_index(drop=True)\n",
    "\n",
    "# ------------------------------\n",
    "# 2. Feature Selection\n",
    "# ------------------------------\n",
    "features = ['temperature']\n",
    "time_features = ['hour', 'day_of_week', 'is_weekend']\n",
    "\n",
    "# Create time-related features\n",
    "data['hour'] = data[timestamp_col].dt.hour\n",
    "data['day_of_week'] = data[timestamp_col].dt.dayofweek\n",
    "data['is_weekend'] = data['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Combine all features\n",
    "data_features = data[features + time_features]\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data_features)\n",
    "\n",
    "# ------------------------------\n",
    "# 3. Define Sequence Parameters\n",
    "# ------------------------------\n",
    "sequence_length = 12\n",
    "prediction_steps = [6, 12, 18, 24, 30, 36, 42, 48]\n",
    "\n",
    "# ------------------------------\n",
    "# 4. Create Sequences and Targets\n",
    "# ------------------------------\n",
    "def create_future_sequences(data, sequence_length, prediction_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - max(prediction_steps)):\n",
    "        X.append(data[i: i + sequence_length])\n",
    "        future_vals = [\n",
    "            np.mean(data[i + sequence_length + p: i + sequence_length + p + 6, 0])  # 0: temperature\n",
    "            for p in prediction_steps\n",
    "        ]\n",
    "        y.append(future_vals)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_future_sequences(data_normalized, sequence_length, prediction_steps)\n",
    "\n",
    "# ------------------------------\n",
    "# 5. Train-Test Split\n",
    "# ------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# ------------------------------\n",
    "# 6. Build GRU Model\n",
    "# ------------------------------\n",
    "input_layer = Input(shape=(sequence_length, len(features + time_features)))\n",
    "\n",
    "x = GRU(128, activation='tanh', return_sequences=True)(input_layer)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = GRU(64, activation='tanh')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(len(prediction_steps), activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ------------------------------\n",
    "# 7. Training\n",
    "# ------------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-6)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=42,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop, lr_scheduler],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 8. Evaluation\n",
    "# ------------------------------\n",
    "def evaluate_predictions(y_true, y_pred, steps):\n",
    "    print(\"\\nStep-wise Performance Evaluation:\")\n",
    "    for idx, step in enumerate(steps):\n",
    "        # 假设每个数据点间隔为10分钟\n",
    "        hours = (step * 10) // 60\n",
    "        minutes = (step * 10) % 60\n",
    "\n",
    "        true_step = y_true[:, idx]\n",
    "        pred_step = y_pred[:, idx]\n",
    "\n",
    "        mae = mean_absolute_error(true_step, pred_step)\n",
    "        r2 = r2_score(true_step, pred_step)\n",
    "        print(f\"预测 {hours}h{minutes:02d}min 后 -> MAE={mae:.4f}, R²={r2:.4f}\")\n",
    "\n",
    "    # 整体评估\n",
    "    overall_mae = mean_absolute_error(y_true, y_pred)\n",
    "    overall_r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
    "    print(\"\\nOverall Performance:\")\n",
    "    print(f\"Overall MAE: {overall_mae:.4f}\")\n",
    "    print(f\"Overall R²: {overall_r2:.4f}\")\n",
    "\n",
    "evaluate_predictions(y_test, y_pred, prediction_steps)\n",
    "\n",
    "# ------------------------------\n",
    "# 9. Save Model and Scaler\n",
    "# ------------------------------\n",
    "model.save('temperature_prediction_gru_model.keras')\n",
    "joblib.dump(scaler, 'temperature_scaler.pkl')\n"
   ],
   "id": "97eebcc64d79b13d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "491/491 [==============================] - 11s 15ms/step - loss: 0.0815 - val_loss: 0.0105 - lr: 0.0010\n",
      "Epoch 2/42\n",
      "491/491 [==============================] - 7s 13ms/step - loss: 0.0144 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 3/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0074 - val_loss: 0.0021 - lr: 0.0010\n",
      "Epoch 4/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0048 - val_loss: 9.9220e-04 - lr: 0.0010\n",
      "Epoch 5/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0036 - val_loss: 0.0010 - lr: 0.0010\n",
      "Epoch 6/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0029 - val_loss: 6.7402e-04 - lr: 0.0010\n",
      "Epoch 7/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0024 - val_loss: 0.0016 - lr: 0.0010\n",
      "Epoch 8/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0022 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 9/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0019 - val_loss: 0.0012 - lr: 0.0010\n",
      "Epoch 10/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0019 - val_loss: 3.2988e-04 - lr: 0.0010\n",
      "Epoch 11/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0016 - val_loss: 6.9078e-04 - lr: 0.0010\n",
      "Epoch 12/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0015 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 13/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0014 - val_loss: 0.0015 - lr: 0.0010\n",
      "Epoch 14/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0013 - val_loss: 0.0013 - lr: 0.0010\n",
      "Epoch 15/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0012 - val_loss: 0.0011 - lr: 0.0010\n",
      "Epoch 16/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0011 - val_loss: 3.5685e-04 - lr: 5.0000e-04\n",
      "Epoch 17/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 0.0010 - val_loss: 2.8554e-04 - lr: 5.0000e-04\n",
      "Epoch 18/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 9.8100e-04 - val_loss: 4.0718e-04 - lr: 5.0000e-04\n",
      "Epoch 19/42\n",
      "491/491 [==============================] - 7s 15ms/step - loss: 9.5355e-04 - val_loss: 0.0015 - lr: 5.0000e-04\n",
      "Epoch 20/42\n",
      "491/491 [==============================] - 7s 15ms/step - loss: 0.0010 - val_loss: 4.4112e-04 - lr: 5.0000e-04\n",
      "Epoch 21/42\n",
      "491/491 [==============================] - 7s 14ms/step - loss: 8.3385e-04 - val_loss: 2.2876e-04 - lr: 2.5000e-04\n",
      "Epoch 22/42\n",
      "491/491 [==============================] - 7s 14ms/step - loss: 8.2259e-04 - val_loss: 3.5929e-04 - lr: 2.5000e-04\n",
      "Epoch 23/42\n",
      "491/491 [==============================] - 7s 14ms/step - loss: 7.6220e-04 - val_loss: 5.6894e-04 - lr: 2.5000e-04\n",
      "Epoch 24/42\n",
      "491/491 [==============================] - 7s 13ms/step - loss: 7.8084e-04 - val_loss: 3.7276e-04 - lr: 2.5000e-04\n",
      "Epoch 25/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 7.4176e-04 - val_loss: 4.7769e-04 - lr: 2.5000e-04\n",
      "Epoch 26/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 7.3302e-04 - val_loss: 6.1250e-04 - lr: 2.5000e-04\n",
      "Epoch 27/42\n",
      "491/491 [==============================] - 6s 13ms/step - loss: 6.8495e-04 - val_loss: 2.3568e-04 - lr: 1.2500e-04\n",
      "Epoch 28/42\n",
      "491/491 [==============================] - 7s 14ms/step - loss: 7.0758e-04 - val_loss: 4.0692e-04 - lr: 1.2500e-04\n",
      "Epoch 29/42\n",
      "491/491 [==============================] - 7s 14ms/step - loss: 6.9635e-04 - val_loss: 6.9285e-04 - lr: 1.2500e-04\n",
      "Epoch 30/42\n",
      "491/491 [==============================] - 7s 14ms/step - loss: 6.5755e-04 - val_loss: 2.8925e-04 - lr: 1.2500e-04\n",
      "Epoch 31/42\n",
      "491/491 [==============================] - 7s 13ms/step - loss: 6.6546e-04 - val_loss: 3.0223e-04 - lr: 1.2500e-04\n",
      "\n",
      "Step-wise Performance Evaluation:\n",
      "预测 1h00min 后 -> MAE=0.0097, R²=0.9783\n",
      "预测 2h00min 后 -> MAE=0.0104, R²=0.9740\n",
      "预测 3h00min 后 -> MAE=0.0100, R²=0.9767\n",
      "预测 4h00min 后 -> MAE=0.0118, R²=0.9672\n",
      "预测 5h00min 后 -> MAE=0.0115, R²=0.9691\n",
      "预测 6h00min 后 -> MAE=0.0142, R²=0.9533\n",
      "预测 7h00min 后 -> MAE=0.0144, R²=0.9551\n",
      "预测 8h00min 后 -> MAE=0.0151, R²=0.9520\n",
      "\n",
      "Overall Performance:\n",
      "Overall MAE: 0.0121\n",
      "Overall R²: 0.9656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['temperature_scaler.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ef5dc9591d882369"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
