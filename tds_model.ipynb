{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-13T12:07:08.693875Z",
     "start_time": "2025-03-13T12:04:51.102922Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. 讀取與基本處理\n",
    "file_path = 'IMPACT.sensors.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "timestamp_column = 'createdAt'\n",
    "data[timestamp_column] = pd.to_datetime(data[timestamp_column])\n",
    "data = data.sort_values(by=timestamp_column)\n",
    "\n",
    "# 2. 將特徵值先四捨五入到兩位小數（若原CSV只有兩位，可省略這一步）\n",
    "features = ['conductivity', 'ppm']\n",
    "data_features = data[features].round(2)\n",
    "\n",
    "# 3. 進行 MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data_features)\n",
    "\n",
    "# 定義sequence參數（同你的原始碼）\n",
    "sequence_length = 12\n",
    "prediction_steps = [6, 12, 18, 24, 30, 36, 42, 48]\n",
    "\n",
    "def create_future_sequences(data, sequence_length, prediction_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - max(prediction_steps)):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        # 以每一段未來時間段的 6 筆資料做平均\n",
    "        future_values = [\n",
    "            np.mean(data[i + sequence_length + p : i + sequence_length + p + 6], axis=0)\n",
    "            for p in prediction_steps\n",
    "        ]\n",
    "        y.append(np.array(future_values).flatten())\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_future_sequences(data_normalized, sequence_length, prediction_steps)\n",
    "\n",
    "# 分訓練、測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 建立 GRU 模型\n",
    "input_layer = Input(shape=(sequence_length, len(features)))\n",
    "x = GRU(64, activation='relu', return_sequences=True)(input_layer)\n",
    "x = GRU(32, activation='relu', return_sequences=False)(x)\n",
    "dense1 = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(len(features) * len(prediction_steps), activation='linear')(dense1)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 5. 訓練\n",
    "history = model.fit(X_train, y_train, epochs=42, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 6. 評估 (在「縮放後」的測試資料上先得到 MSE)\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss (MSE, scaled):\", test_loss)\n",
    "\n",
    "# 7. 預測\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.reshape(y_test.shape)\n",
    "\n",
    "# 8. 反轉換 (inverse_transform) 到原始尺度並取小數點後兩位\n",
    "#\n",
    "#   y_pred, y_test 的 shape: (樣本數, len(features)*len(prediction_steps))\n",
    "#   需要先 reshape 成 (樣本數 * 預測步數, len(features)) 再 inverse_transform\n",
    "#\n",
    "#   這樣做完後才能得到真正「原始尺度」下的預測值\n",
    "def inverse_transform_2dec(y, scaler, features, prediction_steps):\n",
    "    samples = y.shape[0]\n",
    "    n_features = len(features)\n",
    "    n_steps = len(prediction_steps)\n",
    "\n",
    "    # (samples, n_steps*n_features) -> (samples*n_steps, n_features)\n",
    "    y_reshaped = y.reshape(samples * n_steps, n_features)\n",
    "    y_inverted = scaler.inverse_transform(y_reshaped)\n",
    "\n",
    "    # 再 reshape 回 (samples, n_steps*n_features)\n",
    "    y_inverted = y_inverted.reshape(samples, n_steps * n_features)\n",
    "\n",
    "    # 取小數點2位\n",
    "    y_inverted_2dec = np.round(y_inverted, 2)\n",
    "    return y_inverted_2dec\n",
    "\n",
    "y_pred_orig = inverse_transform_2dec(y_pred, scaler, features, prediction_steps)\n",
    "y_test_orig = inverse_transform_2dec(y_test, scaler, features, prediction_steps)\n",
    "\n",
    "# 9. 用「原始尺度」做評估\n",
    "def evaluate_predictions_in_original_scale(y_true_orig, y_pred_orig, features, prediction_steps):\n",
    "    print(\"\\nStep-wise Performance Evaluation (Original Scale):\")\n",
    "    for idx, step in enumerate(prediction_steps):\n",
    "        hours = (step * 10) // 60\n",
    "        minutes = (step * 10) % 60\n",
    "        for feature_idx, feature in enumerate(features):\n",
    "            y_true_step = y_true_orig[:, idx * len(features) + feature_idx]\n",
    "            y_pred_step = y_pred_orig[:, idx * len(features) + feature_idx]\n",
    "\n",
    "            r2 = r2_score(y_true_step, y_pred_step)\n",
    "            mae = mean_absolute_error(y_true_step, y_pred_step)\n",
    "            print(f\"{hours}h{minutes:02d}min - {feature}: R²={r2:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "    overall_r2 = r2_score(y_true_orig.flatten(), y_pred_orig.flatten())\n",
    "    overall_mae = mean_absolute_error(y_true_orig.flatten(), y_pred_orig.flatten())\n",
    "    print(\"\\nOverall Performance (Original Scale):\")\n",
    "    print(f\"Overall R²: {overall_r2:.2f}\")\n",
    "    print(f\"Overall MAE: {overall_mae:.2f}\")\n",
    "\n",
    "evaluate_predictions_in_original_scale(y_test_orig, y_pred_orig, features, prediction_steps)\n",
    "\n",
    "# 10. 保存模型\n",
    "model.save('tds_dissolved_solid_conductivity_gru_model.keras')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "491/491 [==============================] - 6s 7ms/step - loss: 3.7593e-04 - val_loss: 1.1231e-04\n",
      "Epoch 2/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0729e-04 - val_loss: 1.0643e-04\n",
      "Epoch 3/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0442e-04 - val_loss: 1.1339e-04\n",
      "Epoch 4/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 1.0282e-04 - val_loss: 1.0680e-04\n",
      "Epoch 5/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0248e-04 - val_loss: 1.0540e-04\n",
      "Epoch 6/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0263e-04 - val_loss: 1.1330e-04\n",
      "Epoch 7/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0190e-04 - val_loss: 1.0400e-04\n",
      "Epoch 8/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0057e-04 - val_loss: 1.0688e-04\n",
      "Epoch 9/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0059e-04 - val_loss: 1.0084e-04\n",
      "Epoch 10/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0011e-04 - val_loss: 1.0112e-04\n",
      "Epoch 11/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0011e-04 - val_loss: 1.0038e-04\n",
      "Epoch 12/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0038e-04 - val_loss: 1.0421e-04\n",
      "Epoch 13/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9805e-05 - val_loss: 1.0165e-04\n",
      "Epoch 14/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0035e-04 - val_loss: 1.0294e-04\n",
      "Epoch 15/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9876e-05 - val_loss: 9.9628e-05\n",
      "Epoch 16/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0058e-04 - val_loss: 1.0172e-04\n",
      "Epoch 17/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9419e-05 - val_loss: 1.0044e-04\n",
      "Epoch 18/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8783e-05 - val_loss: 1.0445e-04\n",
      "Epoch 19/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0017e-04 - val_loss: 1.0676e-04\n",
      "Epoch 20/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8618e-05 - val_loss: 9.9600e-05\n",
      "Epoch 21/42\n",
      "491/491 [==============================] - 4s 7ms/step - loss: 9.7871e-05 - val_loss: 1.0134e-04\n",
      "Epoch 22/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8458e-05 - val_loss: 1.0120e-04\n",
      "Epoch 23/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 9.8503e-05 - val_loss: 1.0020e-04\n",
      "Epoch 24/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8128e-05 - val_loss: 1.0035e-04\n",
      "Epoch 25/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 9.7515e-05 - val_loss: 1.0128e-04\n",
      "Epoch 26/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 9.7448e-05 - val_loss: 9.9295e-05\n",
      "Epoch 27/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.7096e-05 - val_loss: 9.8751e-05\n",
      "Epoch 28/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.7447e-05 - val_loss: 1.0132e-04\n",
      "Epoch 29/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 9.7710e-05 - val_loss: 1.0199e-04\n",
      "Epoch 30/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6999e-05 - val_loss: 9.9206e-05\n",
      "Epoch 31/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6461e-05 - val_loss: 1.0782e-04\n",
      "Epoch 32/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8014e-05 - val_loss: 9.8853e-05\n",
      "Epoch 33/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6707e-05 - val_loss: 9.7043e-05\n",
      "Epoch 34/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6767e-05 - val_loss: 9.8622e-05\n",
      "Epoch 35/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6750e-05 - val_loss: 1.0088e-04\n",
      "Epoch 36/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5961e-05 - val_loss: 1.0294e-04\n",
      "Epoch 37/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5881e-05 - val_loss: 9.8256e-05\n",
      "Epoch 38/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6204e-05 - val_loss: 9.7386e-05\n",
      "Epoch 39/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5877e-05 - val_loss: 9.7429e-05\n",
      "Epoch 40/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6327e-05 - val_loss: 9.8149e-05\n",
      "Epoch 41/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5262e-05 - val_loss: 9.8042e-05\n",
      "Epoch 42/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5713e-05 - val_loss: 1.0068e-04\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.0068e-04\n",
      "Test Loss (MSE, scaled): 0.00010067705443361774\n",
      "123/123 [==============================] - 1s 2ms/step\n",
      "\n",
      "Step-wise Performance Evaluation (Original Scale):\n",
      "1h00min - conductivity: R²=0.73, MAE=0.00\n",
      "1h00min - ppm: R²=0.94, MAE=1.53\n",
      "2h00min - conductivity: R²=0.51, MAE=0.00\n",
      "2h00min - ppm: R²=0.94, MAE=1.59\n",
      "3h00min - conductivity: R²=0.50, MAE=0.00\n",
      "3h00min - ppm: R²=0.93, MAE=1.82\n",
      "4h00min - conductivity: R²=0.67, MAE=0.00\n",
      "4h00min - ppm: R²=0.92, MAE=2.03\n",
      "5h00min - conductivity: R²=0.65, MAE=0.00\n",
      "5h00min - ppm: R²=0.92, MAE=1.86\n",
      "6h00min - conductivity: R²=0.62, MAE=0.00\n",
      "6h00min - ppm: R²=0.93, MAE=1.91\n",
      "7h00min - conductivity: R²=0.56, MAE=0.00\n",
      "7h00min - ppm: R²=0.92, MAE=1.88\n",
      "8h00min - conductivity: R²=0.55, MAE=0.00\n",
      "8h00min - ppm: R²=0.91, MAE=1.95\n",
      "\n",
      "Overall Performance (Original Scale):\n",
      "Overall R²: 1.00\n",
      "Overall MAE: 0.91\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-14T08:22:55.491468Z",
     "start_time": "2025-03-14T08:20:40.030182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, GRU, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# 1. 讀取與基本處理\n",
    "file_path = 'IMPACT.sensors.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "timestamp_column = 'createdAt'\n",
    "data[timestamp_column] = pd.to_datetime(data[timestamp_column])\n",
    "data = data.sort_values(by=timestamp_column)\n",
    "\n",
    "# 2. 選擇特徵並四捨五入到兩位小數\n",
    "features = ['conductivity', 'ppm']\n",
    "data_features = data[features].round(2)\n",
    "\n",
    "# 3. 進行 MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data_normalized = scaler.fit_transform(data_features)\n",
    "\n",
    "# **儲存 Scaler**\n",
    "scaler_filename = \"tds_dissolved_solid_conductivity_scaler.pkl\"\n",
    "joblib.dump(scaler, scaler_filename)\n",
    "print(f\"Scaler saved as {scaler_filename}\")\n",
    "\n",
    "# 定義 sequence 參數\n",
    "sequence_length = 12\n",
    "prediction_steps = [6, 12, 18, 24, 30, 36, 42, 48]\n",
    "\n",
    "def create_future_sequences(data, sequence_length, prediction_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - sequence_length - max(prediction_steps)):\n",
    "        X.append(data[i:i + sequence_length])\n",
    "        # 以每一段未來時間段的 6 筆資料做平均\n",
    "        future_values = [\n",
    "            np.mean(data[i + sequence_length + p : i + sequence_length + p + 6], axis=0)\n",
    "            for p in prediction_steps\n",
    "        ]\n",
    "        y.append(np.array(future_values).flatten())\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_future_sequences(data_normalized, sequence_length, prediction_steps)\n",
    "\n",
    "# 分訓練、測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. 建立 GRU 模型\n",
    "input_layer = Input(shape=(sequence_length, len(features)))\n",
    "x = GRU(64, activation='relu', return_sequences=True)(input_layer)\n",
    "x = GRU(32, activation='relu', return_sequences=False)(x)\n",
    "dense1 = Dense(64, activation='relu')(x)\n",
    "output_layer = Dense(len(features) * len(prediction_steps), activation='linear')(dense1)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# 5. 訓練\n",
    "history = model.fit(X_train, y_train, epochs=42, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 6. 評估\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss (MSE, scaled):\", test_loss)\n",
    "\n",
    "# 7. 預測\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.reshape(y_test.shape)\n",
    "\n",
    "# 8. 反轉換 (inverse_transform) 到原始尺度並取小數點後兩位\n",
    "def inverse_transform_2dec(y, scaler, features, prediction_steps):\n",
    "    samples = y.shape[0]\n",
    "    n_features = len(features)\n",
    "    n_steps = len(prediction_steps)\n",
    "\n",
    "    # (samples, n_steps*n_features) -> (samples*n_steps, n_features)\n",
    "    y_reshaped = y.reshape(samples * n_steps, n_features)\n",
    "    y_inverted = scaler.inverse_transform(y_reshaped)\n",
    "\n",
    "    # 再 reshape 回 (samples, n_steps*n_features)\n",
    "    y_inverted = y_inverted.reshape(samples, n_steps * n_features)\n",
    "\n",
    "    # 取小數點2位\n",
    "    y_inverted_2dec = np.round(y_inverted, 2)\n",
    "    return y_inverted_2dec\n",
    "\n",
    "y_pred_orig = inverse_transform_2dec(y_pred, scaler, features, prediction_steps)\n",
    "y_test_orig = inverse_transform_2dec(y_test, scaler, features, prediction_steps)\n",
    "\n",
    "# 9. 用「原始尺度」做評估\n",
    "def evaluate_predictions_in_original_scale(y_true_orig, y_pred_orig, features, prediction_steps):\n",
    "    print(\"\\nStep-wise Performance Evaluation (Original Scale):\")\n",
    "    for idx, step in enumerate(prediction_steps):\n",
    "        hours = (step * 10) // 60\n",
    "        minutes = (step * 10) % 60\n",
    "        for feature_idx, feature in enumerate(features):\n",
    "            y_true_step = y_true_orig[:, idx * len(features) + feature_idx]\n",
    "            y_pred_step = y_pred_orig[:, idx * len(features) + feature_idx]\n",
    "\n",
    "            r2 = r2_score(y_true_step, y_pred_step)\n",
    "            mae = mean_absolute_error(y_true_step, y_pred_step)\n",
    "            print(f\"{hours}h{minutes:02d}min - {feature}: R²={r2:.2f}, MAE={mae:.2f}\")\n",
    "\n",
    "    overall_r2 = r2_score(y_true_orig.flatten(), y_pred_orig.flatten())\n",
    "    overall_mae = mean_absolute_error(y_true_orig.flatten(), y_pred_orig.flatten())\n",
    "    print(\"\\nOverall Performance (Original Scale):\")\n",
    "    print(f\"Overall R²: {overall_r2:.2f}\")\n",
    "    print(f\"Overall MAE: {overall_mae:.2f}\")\n",
    "\n",
    "evaluate_predictions_in_original_scale(y_test_orig, y_pred_orig, features, prediction_steps)\n",
    "\n",
    "# 10. 保存模型\n",
    "model.save('tds_dissolved_solid_conductivity_gru_model.keras')"
   ],
   "id": "bfc3d60c1d5b355e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved as scaler_conductivity_ppm.pkl\n",
      "Epoch 1/42\n",
      "491/491 [==============================] - 6s 7ms/step - loss: 3.6139e-04 - val_loss: 1.3957e-04\n",
      "Epoch 2/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 1.1127e-04 - val_loss: 1.0556e-04\n",
      "Epoch 3/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 1.0396e-04 - val_loss: 1.0346e-04\n",
      "Epoch 4/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 1.0275e-04 - val_loss: 1.1029e-04\n",
      "Epoch 5/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 1.0212e-04 - val_loss: 1.0879e-04\n",
      "Epoch 6/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0182e-04 - val_loss: 1.0463e-04\n",
      "Epoch 7/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 1.0103e-04 - val_loss: 1.0249e-04\n",
      "Epoch 8/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0081e-04 - val_loss: 1.0132e-04\n",
      "Epoch 9/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0090e-04 - val_loss: 1.0094e-04\n",
      "Epoch 10/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0092e-04 - val_loss: 1.0144e-04\n",
      "Epoch 11/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9781e-05 - val_loss: 1.0129e-04\n",
      "Epoch 12/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0053e-04 - val_loss: 1.0886e-04\n",
      "Epoch 13/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9941e-05 - val_loss: 1.0280e-04\n",
      "Epoch 14/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 1.0015e-04 - val_loss: 1.0247e-04\n",
      "Epoch 15/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8802e-05 - val_loss: 1.0567e-04\n",
      "Epoch 16/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9821e-05 - val_loss: 9.9905e-05\n",
      "Epoch 17/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9262e-05 - val_loss: 1.0457e-04\n",
      "Epoch 18/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.9114e-05 - val_loss: 1.0101e-04\n",
      "Epoch 19/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 9.7917e-05 - val_loss: 9.9472e-05\n",
      "Epoch 20/42\n",
      "491/491 [==============================] - 3s 7ms/step - loss: 9.8868e-05 - val_loss: 1.0262e-04\n",
      "Epoch 21/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8694e-05 - val_loss: 1.1343e-04\n",
      "Epoch 22/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.8062e-05 - val_loss: 1.0661e-04\n",
      "Epoch 23/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.7370e-05 - val_loss: 9.8438e-05\n",
      "Epoch 24/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.7856e-05 - val_loss: 1.0100e-04\n",
      "Epoch 25/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.7163e-05 - val_loss: 1.0211e-04\n",
      "Epoch 26/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6782e-05 - val_loss: 9.9389e-05\n",
      "Epoch 27/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.7293e-05 - val_loss: 1.0054e-04\n",
      "Epoch 28/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6940e-05 - val_loss: 9.7533e-05\n",
      "Epoch 29/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6976e-05 - val_loss: 1.0032e-04\n",
      "Epoch 30/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6833e-05 - val_loss: 1.0855e-04\n",
      "Epoch 31/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6256e-05 - val_loss: 1.0936e-04\n",
      "Epoch 32/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6743e-05 - val_loss: 9.9672e-05\n",
      "Epoch 33/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5731e-05 - val_loss: 9.8957e-05\n",
      "Epoch 34/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6574e-05 - val_loss: 1.0524e-04\n",
      "Epoch 35/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6196e-05 - val_loss: 9.8571e-05\n",
      "Epoch 36/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5913e-05 - val_loss: 1.0100e-04\n",
      "Epoch 37/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.6017e-05 - val_loss: 9.8823e-05\n",
      "Epoch 38/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5774e-05 - val_loss: 1.0093e-04\n",
      "Epoch 39/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.5315e-05 - val_loss: 1.0008e-04\n",
      "Epoch 40/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.4827e-05 - val_loss: 9.6969e-05\n",
      "Epoch 41/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.4763e-05 - val_loss: 1.0023e-04\n",
      "Epoch 42/42\n",
      "491/491 [==============================] - 3s 6ms/step - loss: 9.4828e-05 - val_loss: 1.0238e-04\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 1.0238e-04\n",
      "Test Loss (MSE, scaled): 0.00010238006507279351\n",
      "123/123 [==============================] - 1s 2ms/step\n",
      "\n",
      "Step-wise Performance Evaluation (Original Scale):\n",
      "1h00min - conductivity: R²=0.76, MAE=0.00\n",
      "1h00min - ppm: R²=0.94, MAE=1.52\n",
      "2h00min - conductivity: R²=0.50, MAE=0.00\n",
      "2h00min - ppm: R²=0.94, MAE=1.68\n",
      "3h00min - conductivity: R²=0.52, MAE=0.00\n",
      "3h00min - ppm: R²=0.93, MAE=1.84\n",
      "4h00min - conductivity: R²=0.65, MAE=0.00\n",
      "4h00min - ppm: R²=0.93, MAE=2.03\n",
      "5h00min - conductivity: R²=0.65, MAE=0.00\n",
      "5h00min - ppm: R²=0.92, MAE=2.00\n",
      "6h00min - conductivity: R²=0.62, MAE=0.00\n",
      "6h00min - ppm: R²=0.93, MAE=1.90\n",
      "7h00min - conductivity: R²=0.55, MAE=0.00\n",
      "7h00min - ppm: R²=0.92, MAE=2.04\n",
      "8h00min - conductivity: R²=0.54, MAE=0.00\n",
      "8h00min - ppm: R²=0.91, MAE=2.12\n",
      "\n",
      "Overall Performance (Original Scale):\n",
      "Overall R²: 1.00\n",
      "Overall MAE: 0.95\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be8773724051f5ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
